---
---
@article{Zand2024,
   abstract = {This research adopts a multidisciplinary approach, synthesizing insights from psychology, technology, and ethics to unravel the intricate threads of diverse gender perceptions regarding trust-building, privacy considerations, and safety concerns in Human-Robot Interaction (HRI). Our study contributes to a holistic understanding of HRI dynamics, providing valuable insights for designing robots to assist individuals with their Activities of Daily Living (ADL) at home, including tasks such as preparing their daily meals independently. This study delves into the correlation between robot failures and gender perceptions of trust, privacy, and safety when a human communicates with a robot in a natural way by using unstructured speech. In this approach, the user commands the robot conversationally using natural spoken language to fetch cooking-related items in a research lab's mocked-up kitchen. With a participant pool of 35 adults (13 females with an average age of 35.58 ± 12.06 and 22 males with an average age of 35.68 ± 15.35), Kendall's Tau correlations are employed for statistical analysis, offering a comprehensive investigation into the intricate interplay of gender, interaction methods, and perceptions in the realm of human-robot dynamics.},
   author = {Manizheh Zand and Krishna Kodur and Sean Banerjee and Natasha Banerjee and Maria Kyrarini},
   doi = {10.1145/3652037.3652078},
   isbn = {9798400717604},
   journal = {ACM International Conference Proceeding Series},
   keywords = {Ethical Considerations,Gender,Human-Robot Interaction,Trust,Usability},
   month = {6},
   pages = {74-79},
   publisher = {Association for Computing Machinery},
   title = {Examining Diverse Gender Dynamics in Human-Robot Interaction: Trust Privacy and Safety Perceptions},
   url = {https://dl.acm.org/doi/10.1145/3652037.3652078},
   year = {2024},
   selected={true}
}
@article{Zand2023,
   abstract = {For people who are blind or visually impaired, it is complicated to attend an in-person professional event, such as workshops or conferences, and initiate conversations with other attendees. This paper proposes TalkConnect, a novel mobile application that aims to empower individuals with visual impairments or blindness to identify other participants in the event, initiate communication, and request in-person meetings. The prototype of the app is presented, and its design and characteristics are discussed.},
   author = {Manizheh Zand and Joyce Ayoola and Roopan Tuli and Akshat Kalra and John Quach and Maria Kyrarini},
   doi = {10.1145/3594806.3594831},
   isbn = {9798400700699},
   journal = {ACM International Conference Proceeding Series},
   keywords = {accessibility,assistive technology,augmenting social interactions,blind,mobile app,visually impaired,voice control},
   month = {7},
   pages = {6-9},
   publisher = {Association for Computing Machinery},
   title = {TalkConnect: A Mobile Networking App for People with Visual Impairments Attending In-person Formal Events},
   url = {https://dl.acm.org/doi/10.1145/3594806.3594831},
   year = {2023},
   selected={true}
}

@article{Kodur2023,
   abstract = {This research delves into user preferences concerning structured (the subject follows an exact script to command the robot) and unstructured (the subject commands the robot in a conversational way) robot interaction through natural spoken language. Data was gathered from 30 adult participants who completed two distinct tasks involving both structured and unstructured commands. The study examines correlations between robot errors and user perceptions, as well as how past or present failures impact participants' perception of robot utility. Three hypotheses are formulated, and the paper offers a comprehensive overview of the study's aims, methodologies, and principal findings, which were ascertained using paired t-Test and Kendall-Tau correlations. The study indicates that participants showed a preference for the unstructured task in contrast to the structured one. Analysis of the data revealed interesting correlations between the user perception of the robot and the robot errors. This work has been submitted to the IEEE for possible publication. Abstract-This research delves into user preferences concerning structured (the subject follows an exact script to command the robot) and unstructured (the subject commands the robot in a conversational way) robot interaction through natural spoken language. Data was gathered from 30 adult participants who completed two distinct tasks involving both structured and unstructured commands. The study examines correlations between robot errors and user perceptions, as well as how past or present failures impact participants' perception of robot utility. Three hypotheses are formulated, and the paper offers a comprehensive overview of the study's aims, methodologies, and principal findings, which were ascertained using paired t-Test and Kendall-Tau correlations. The study indicates that participants showed a preference for the unstructured task in contrast to the structured one. Analysis of the data revealed interesting correlations between the user perception of the robot and the robot errors.},
   author = {Krishna Kodur and Manizheh Zand and Matthew Tognotti and Cinthya Jauregui and Maria Kyrarini},
   doi = {10.36227/techrxiv.24022452.v1},
   keywords = {Human-Robot In-terface,Human-Robot Interaction,Index Terms-Structured Speech,Large Language Models,Natural Language Processing,Unstructured Speech,User Preferences,Voice commands},
   title = {Structured and Unstructured Speech2Action Frameworks for Human-Robot Collaboration: A User Study},
   url = {https://doi.org/10.36227/techrxiv.24022452.v1},
   year = {2020},
   selected={true}
}

@article{Zand2023,
   abstract = {Robots have the potential to assist people in daily tasks, such as cooking a meal. Communicating with the robots verbally and in an unstructured way is important, as spoken language is the main form of communication for humans. This paper proposes a novel framework that automatically generates robot actions from unstructured speech. The proposed frame-work was evaluated by collecting data from 15 participants preparing their meals while seating on a chair in a randomly disrupted environment. The system can identify and respond to a task sequence while the user may be engaged in unrelated conversations, even if the user's speech might be unstructured and grammatically incorrect. The accuracy of the proposed system is 98.6%, which is a very promising finding.},
   author = {Manizheh Zand and Krishna Kodur and Maria Kyrarini},
   doi = {10.1109/ICARA56516.2023.10125800},
   isbn = {9781665489218},
   journal = {2023 9th International Conference on Automation, Robotics and Applications, ICARA 2023},
   keywords = {Assistive Cooking,Human-robot collaboration,Natural Language Processing,Robot Action Generation,Speech},
   pages = {155-159},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Automatic Generation of Robot Actions for Collaborative Tasks from Speech},
   year = {2023},
   selected={true}
}

@inproceedings{Kodur_2023,
  title={Towards Robot Learning from Spoken Language},
  author={Kodur, Krishna and Zand, Manizheh and Kyrarini, Maria},
  booktitle={Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={112--116},
  year={2023},
  publisher = {ACM},
  address = {New York, NY},
  selected={true}
}





